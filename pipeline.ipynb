{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Pipeline for object detection and tracking in 3D:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Required packages:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "from sort import Sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Definition of Objects and Functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2D Object detection : YOLOV5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 000000.png\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 1 truck, 666.4ms\n",
      "Speed: 2.9ms preprocess, 666.4ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000000.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000000.png\n",
      "\n",
      "Processing: 000001.png\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 1 truck, 595.0ms\n",
      "Speed: 1.4ms preprocess, 595.0ms inference, 0.6ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000001.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000001.png\n",
      "\n",
      "Processing: 000002.png\n",
      "\n",
      "0: 224x640 4 persons, 2 bicycles, 1 truck, 606.2ms\n",
      "Speed: 1.6ms preprocess, 606.2ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000002.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000002.png\n",
      "\n",
      "Processing: 000003.png\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 1 truck, 593.7ms\n",
      "Speed: 1.4ms preprocess, 593.7ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000003.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000003.png\n",
      "\n",
      "Processing: 000004.png\n",
      "\n",
      "0: 224x640 3 persons, 1 bicycle, 1 truck, 604.0ms\n",
      "Speed: 1.8ms preprocess, 604.0ms inference, 0.6ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000004.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000004.png\n",
      "\n",
      "Processing: 000005.png\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 1 truck, 722.1ms\n",
      "Speed: 1.5ms preprocess, 722.1ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000005.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000005.png\n",
      "\n",
      "Processing: 000006.png\n",
      "\n",
      "0: 224x640 4 persons, 3 bicycles, 1 truck, 873.2ms\n",
      "Speed: 1.7ms preprocess, 873.2ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000006.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000006.png\n",
      "\n",
      "Processing: 000007.png\n",
      "\n",
      "0: 224x640 4 persons, 3 bicycles, 1 truck, 780.3ms\n",
      "Speed: 1.5ms preprocess, 780.3ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000007.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000007.png\n",
      "\n",
      "Processing: 000008.png\n",
      "\n",
      "0: 224x640 4 persons, 1 truck, 653.6ms\n",
      "Speed: 3.2ms preprocess, 653.6ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000008.png:\n",
      "Saved: outputs/000008.png\n",
      "\n",
      "Processing: 000009.png\n",
      "\n",
      "0: 224x640 3 persons, 1 bicycle, 1 truck, 757.1ms\n",
      "Speed: 1.4ms preprocess, 757.1ms inference, 4.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000009.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000009.png\n",
      "\n",
      "Processing: 000010.png\n",
      "\n",
      "0: 224x640 3 persons, 1 bicycle, 1 truck, 939.3ms\n",
      "Speed: 2.8ms preprocess, 939.3ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000010.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000010.png\n",
      "\n",
      "Processing: 000011.png\n",
      "\n",
      "0: 224x640 4 persons, 1 truck, 614.5ms\n",
      "Speed: 2.2ms preprocess, 614.5ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000011.png:\n",
      "Saved: outputs/000011.png\n",
      "\n",
      "Processing: 000012.png\n",
      "\n",
      "0: 224x640 5 persons, 2 bicycles, 1 truck, 662.3ms\n",
      "Speed: 4.8ms preprocess, 662.3ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000012.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000012.png\n",
      "\n",
      "Processing: 000013.png\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 1 truck, 628.9ms\n",
      "Speed: 1.6ms preprocess, 628.9ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000013.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000013.png\n",
      "\n",
      "Processing: 000014.png\n",
      "\n",
      "0: 224x640 7 persons, 1 bicycle, 1 truck, 615.1ms\n",
      "Speed: 2.5ms preprocess, 615.1ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000014.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000014.png\n",
      "\n",
      "Processing: 000015.png\n",
      "\n",
      "0: 224x640 9 persons, 1 bicycle, 1 truck, 622.0ms\n",
      "Speed: 1.6ms preprocess, 622.0ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000015.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000015.png\n",
      "\n",
      "Processing: 000016.png\n",
      "\n",
      "0: 224x640 9 persons, 1 bicycle, 1 truck, 619.1ms\n",
      "Speed: 1.7ms preprocess, 619.1ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000016.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000016.png\n",
      "\n",
      "Processing: 000017.png\n",
      "\n",
      "0: 224x640 7 persons, 1 truck, 613.7ms\n",
      "Speed: 1.5ms preprocess, 613.7ms inference, 0.6ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000017.png:\n",
      "Saved: outputs/000017.png\n",
      "\n",
      "Processing: 000018.png\n",
      "\n",
      "0: 224x640 8 persons, 1 truck, 616.0ms\n",
      "Speed: 1.4ms preprocess, 616.0ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000018.png:\n",
      "Saved: outputs/000018.png\n",
      "\n",
      "Processing: 000019.png\n",
      "\n",
      "0: 224x640 8 persons, 1 truck, 657.4ms\n",
      "Speed: 1.6ms preprocess, 657.4ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000019.png:\n",
      "Saved: outputs/000019.png\n",
      "\n",
      "Processing: 000020.png\n",
      "\n",
      "0: 224x640 10 persons, 1 truck, 753.6ms\n",
      "Speed: 1.5ms preprocess, 753.6ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000020.png:\n",
      "Saved: outputs/000020.png\n",
      "\n",
      "Processing: 000021.png\n",
      "\n",
      "0: 224x640 10 persons, 1 truck, 710.9ms\n",
      "Speed: 2.2ms preprocess, 710.9ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000021.png:\n",
      "Saved: outputs/000021.png\n",
      "\n",
      "Processing: 000022.png\n",
      "\n",
      "0: 224x640 9 persons, 1 truck, 615.2ms\n",
      "Speed: 1.5ms preprocess, 615.2ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000022.png:\n",
      "Saved: outputs/000022.png\n",
      "\n",
      "Processing: 000023.png\n",
      "\n",
      "0: 224x640 8 persons, 1 bicycle, 1 truck, 632.0ms\n",
      "Speed: 1.5ms preprocess, 632.0ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000023.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000023.png\n",
      "\n",
      "Processing: 000024.png\n",
      "\n",
      "0: 224x640 10 persons, 1 truck, 1032.1ms\n",
      "Speed: 1.5ms preprocess, 1032.1ms inference, 3.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000024.png:\n",
      "Saved: outputs/000024.png\n",
      "\n",
      "Processing: 000025.png\n",
      "\n",
      "0: 224x640 10 persons, 1 bicycle, 1 truck, 630.1ms\n",
      "Speed: 2.5ms preprocess, 630.1ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000025.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000025.png\n",
      "\n",
      "Processing: 000026.png\n",
      "\n",
      "0: 224x640 9 persons, 1 bicycle, 1 truck, 644.4ms\n",
      "Speed: 1.6ms preprocess, 644.4ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000026.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000026.png\n",
      "\n",
      "Processing: 000027.png\n",
      "\n",
      "0: 224x640 9 persons, 1 bicycle, 1 truck, 621.7ms\n",
      "Speed: 1.5ms preprocess, 621.7ms inference, 2.1ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000027.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000027.png\n",
      "\n",
      "Processing: 000028.png\n",
      "\n",
      "0: 224x640 7 persons, 1 bicycle, 1 truck, 628.6ms\n",
      "Speed: 1.7ms preprocess, 628.6ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000028.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000028.png\n",
      "\n",
      "Processing: 000029.png\n",
      "\n",
      "0: 224x640 7 persons, 2 bicycles, 1 truck, 619.9ms\n",
      "Speed: 1.5ms preprocess, 619.9ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000029.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000029.png\n",
      "\n",
      "Processing: 000030.png\n",
      "\n",
      "0: 224x640 8 persons, 1 bicycle, 1 truck, 622.2ms\n",
      "Speed: 1.6ms preprocess, 622.2ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000030.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000030.png\n",
      "\n",
      "Processing: 000031.png\n",
      "\n",
      "0: 224x640 7 persons, 1 bicycle, 1 truck, 619.1ms\n",
      "Speed: 1.5ms preprocess, 619.1ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000031.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000031.png\n",
      "\n",
      "Processing: 000032.png\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 1 truck, 621.9ms\n",
      "Speed: 1.7ms preprocess, 621.9ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000032.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000032.png\n",
      "\n",
      "Processing: 000033.png\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 1 truck, 625.3ms\n",
      "Speed: 2.3ms preprocess, 625.3ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000033.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000033.png\n",
      "\n",
      "Processing: 000034.png\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 1 truck, 636.3ms\n",
      "Speed: 1.4ms preprocess, 636.3ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000034.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000034.png\n",
      "\n",
      "Processing: 000035.png\n",
      "\n",
      "0: 224x640 7 persons, 1 bicycle, 1 truck, 870.5ms\n",
      "Speed: 1.5ms preprocess, 870.5ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000035.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000035.png\n",
      "\n",
      "Processing: 000036.png\n",
      "\n",
      "0: 224x640 7 persons, 1 bicycle, 1 truck, 631.1ms\n",
      "Speed: 1.6ms preprocess, 631.1ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000036.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000036.png\n",
      "\n",
      "Processing: 000037.png\n",
      "\n",
      "0: 224x640 7 persons, 1 bicycle, 1 truck, 620.3ms\n",
      "Speed: 1.4ms preprocess, 620.3ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000037.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000037.png\n",
      "\n",
      "Processing: 000038.png\n",
      "\n",
      "0: 224x640 7 persons, 3 bicycles, 1 truck, 804.8ms\n",
      "Speed: 1.6ms preprocess, 804.8ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000038.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000038.png\n",
      "\n",
      "Processing: 000039.png\n",
      "\n",
      "0: 224x640 5 persons, 2 bicycles, 1 truck, 715.7ms\n",
      "Speed: 1.6ms preprocess, 715.7ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000039.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000039.png\n",
      "\n",
      "Processing: 000040.png\n",
      "\n",
      "0: 224x640 6 persons, 2 bicycles, 1 truck, 664.8ms\n",
      "Speed: 1.4ms preprocess, 664.8ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000040.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000040.png\n",
      "\n",
      "Processing: 000041.png\n",
      "\n",
      "0: 224x640 6 persons, 3 bicycles, 1 truck, 652.2ms\n",
      "Speed: 1.9ms preprocess, 652.2ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000041.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000041.png\n",
      "\n",
      "Processing: 000042.png\n",
      "\n",
      "0: 224x640 8 persons, 1 bicycle, 1 truck, 705.9ms\n",
      "Speed: 2.8ms preprocess, 705.9ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000042.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000042.png\n",
      "\n",
      "Processing: 000043.png\n",
      "\n",
      "0: 224x640 6 persons, 3 bicycles, 1 truck, 616.9ms\n",
      "Speed: 1.4ms preprocess, 616.9ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000043.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000043.png\n",
      "\n",
      "Processing: 000044.png\n",
      "\n",
      "0: 224x640 6 persons, 2 bicycles, 1 truck, 621.1ms\n",
      "Speed: 1.5ms preprocess, 621.1ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000044.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000044.png\n",
      "\n",
      "Processing: 000045.png\n",
      "\n",
      "0: 224x640 7 persons, 1 bicycle, 1 truck, 615.6ms\n",
      "Speed: 1.4ms preprocess, 615.6ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000045.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000045.png\n",
      "\n",
      "Processing: 000046.png\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 1 truck, 630.4ms\n",
      "Speed: 1.4ms preprocess, 630.4ms inference, 1.6ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000046.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000046.png\n",
      "\n",
      "Processing: 000047.png\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 1 truck, 639.2ms\n",
      "Speed: 1.5ms preprocess, 639.2ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000047.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000047.png\n",
      "\n",
      "Processing: 000048.png\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 1 truck, 886.2ms\n",
      "Speed: 2.0ms preprocess, 886.2ms inference, 0.6ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000048.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000048.png\n",
      "\n",
      "Processing: 000049.png\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 1 truck, 1142.3ms\n",
      "Speed: 1.7ms preprocess, 1142.3ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000049.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000049.png\n",
      "\n",
      "Processing: 000050.png\n",
      "\n",
      "0: 224x640 7 persons, 1 bicycle, 1 truck, 621.8ms\n",
      "Speed: 1.6ms preprocess, 621.8ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000050.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000050.png\n",
      "\n",
      "Processing: 000051.png\n",
      "\n",
      "0: 224x640 7 persons, 1 bicycle, 1 truck, 626.4ms\n",
      "Speed: 1.4ms preprocess, 626.4ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000051.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000051.png\n",
      "\n",
      "Processing: 000052.png\n",
      "\n",
      "0: 224x640 7 persons, 1 bicycle, 1 truck, 649.3ms\n",
      "Speed: 1.8ms preprocess, 649.3ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000052.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000052.png\n",
      "\n",
      "Processing: 000053.png\n",
      "\n",
      "0: 224x640 7 persons, 1 bicycle, 1 truck, 621.1ms\n",
      "Speed: 1.4ms preprocess, 621.1ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000053.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000053.png\n",
      "\n",
      "Processing: 000054.png\n",
      "\n",
      "0: 224x640 8 persons, 1 bicycle, 1 truck, 622.0ms\n",
      "Speed: 1.4ms preprocess, 622.0ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000054.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000054.png\n",
      "\n",
      "Processing: 000055.png\n",
      "\n",
      "0: 224x640 9 persons, 2 bicycles, 1 truck, 629.7ms\n",
      "Speed: 3.8ms preprocess, 629.7ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000055.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000055.png\n",
      "\n",
      "Processing: 000056.png\n",
      "\n",
      "0: 224x640 8 persons, 2 bicycles, 1 truck, 615.7ms\n",
      "Speed: 3.0ms preprocess, 615.7ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000056.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000056.png\n",
      "\n",
      "Processing: 000057.png\n",
      "\n",
      "0: 224x640 9 persons, 1 truck, 618.1ms\n",
      "Speed: 1.4ms preprocess, 618.1ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000057.png:\n",
      "Saved: outputs/000057.png\n",
      "\n",
      "Processing: 000058.png\n",
      "\n",
      "0: 224x640 8 persons, 1 bicycle, 1 truck, 625.7ms\n",
      "Speed: 1.5ms preprocess, 625.7ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000058.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000058.png\n",
      "\n",
      "Processing: 000059.png\n",
      "\n",
      "0: 224x640 9 persons, 1 bicycle, 1 truck, 626.3ms\n",
      "Speed: 2.1ms preprocess, 626.3ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000059.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000059.png\n",
      "\n",
      "Processing: 000060.png\n",
      "\n",
      "0: 224x640 7 persons, 1 bicycle, 1 truck, 628.2ms\n",
      "Speed: 1.9ms preprocess, 628.2ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000060.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000060.png\n",
      "\n",
      "Processing: 000061.png\n",
      "\n",
      "0: 224x640 8 persons, 1 bicycle, 1 truck, 627.8ms\n",
      "Speed: 1.4ms preprocess, 627.8ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000061.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000061.png\n",
      "\n",
      "Processing: 000062.png\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 1 truck, 657.0ms\n",
      "Speed: 1.8ms preprocess, 657.0ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000062.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000062.png\n",
      "\n",
      "Processing: 000063.png\n",
      "\n",
      "0: 224x640 7 persons, 1 bicycle, 1 truck, 751.1ms\n",
      "Speed: 1.5ms preprocess, 751.1ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000063.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000063.png\n",
      "\n",
      "Processing: 000064.png\n",
      "\n",
      "0: 224x640 7 persons, 1 bicycle, 1 truck, 617.2ms\n",
      "Speed: 1.4ms preprocess, 617.2ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000064.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000064.png\n",
      "\n",
      "Processing: 000065.png\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 1 truck, 617.9ms\n",
      "Speed: 1.5ms preprocess, 617.9ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000065.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000065.png\n",
      "\n",
      "Processing: 000066.png\n",
      "\n",
      "0: 224x640 7 persons, 1 bicycle, 1 truck, 651.8ms\n",
      "Speed: 2.1ms preprocess, 651.8ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000066.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000066.png\n",
      "\n",
      "Processing: 000067.png\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 1 truck, 618.0ms\n",
      "Speed: 1.4ms preprocess, 618.0ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000067.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000067.png\n",
      "\n",
      "Processing: 000068.png\n",
      "\n",
      "0: 224x640 6 persons, 2 bicycles, 1 truck, 628.1ms\n",
      "Speed: 1.9ms preprocess, 628.1ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000068.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000068.png\n",
      "\n",
      "Processing: 000069.png\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 1 truck, 633.6ms\n",
      "Speed: 1.5ms preprocess, 633.6ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000069.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000069.png\n",
      "\n",
      "Processing: 000070.png\n",
      "\n",
      "0: 224x640 6 persons, 2 bicycles, 1 truck, 642.1ms\n",
      "Speed: 1.7ms preprocess, 642.1ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000070.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000070.png\n",
      "\n",
      "Processing: 000071.png\n",
      "\n",
      "0: 224x640 5 persons, 2 bicycles, 1 truck, 619.0ms\n",
      "Speed: 2.1ms preprocess, 619.0ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000071.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000071.png\n",
      "\n",
      "Processing: 000072.png\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 1 truck, 619.9ms\n",
      "Speed: 1.4ms preprocess, 619.9ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000072.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000072.png\n",
      "\n",
      "Processing: 000073.png\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 1 truck, 617.4ms\n",
      "Speed: 1.5ms preprocess, 617.4ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000073.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000073.png\n",
      "\n",
      "Processing: 000074.png\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 1 truck, 615.8ms\n",
      "Speed: 1.5ms preprocess, 615.8ms inference, 0.6ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000074.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000074.png\n",
      "\n",
      "Processing: 000075.png\n",
      "\n",
      "0: 224x640 5 persons, 2 bicycles, 1 truck, 614.5ms\n",
      "Speed: 2.5ms preprocess, 614.5ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000075.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000075.png\n",
      "\n",
      "Processing: 000076.png\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 1 truck, 990.5ms\n",
      "Speed: 1.7ms preprocess, 990.5ms inference, 2.5ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000076.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000076.png\n",
      "\n",
      "Processing: 000077.png\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 1 truck, 674.4ms\n",
      "Speed: 1.7ms preprocess, 674.4ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000077.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000077.png\n",
      "\n",
      "Processing: 000078.png\n",
      "\n",
      "0: 224x640 4 persons, 2 bicycles, 1 truck, 683.6ms\n",
      "Speed: 1.4ms preprocess, 683.6ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000078.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000078.png\n",
      "\n",
      "Processing: 000079.png\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 1 truck, 924.5ms\n",
      "Speed: 1.6ms preprocess, 924.5ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000079.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000079.png\n",
      "\n",
      "Processing: 000080.png\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 1 truck, 932.4ms\n",
      "Speed: 1.8ms preprocess, 932.4ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000080.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000080.png\n",
      "\n",
      "Processing: 000081.png\n",
      "\n",
      "0: 224x640 7 persons, 1 bicycle, 1 truck, 1896.8ms\n",
      "Speed: 1.4ms preprocess, 1896.8ms inference, 1.1ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000081.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000081.png\n",
      "\n",
      "Processing: 000082.png\n",
      "\n",
      "0: 224x640 7 persons, 1 bicycle, 1 truck, 853.0ms\n",
      "Speed: 1.9ms preprocess, 853.0ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000082.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000082.png\n",
      "\n",
      "Processing: 000083.png\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 1 truck, 634.5ms\n",
      "Speed: 1.7ms preprocess, 634.5ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000083.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000083.png\n",
      "\n",
      "Processing: 000084.png\n",
      "\n",
      "0: 224x640 7 persons, 2 bicycles, 1 truck, 678.6ms\n",
      "Speed: 2.1ms preprocess, 678.6ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000084.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000084.png\n",
      "\n",
      "Processing: 000085.png\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 1 truck, 634.1ms\n",
      "Speed: 1.8ms preprocess, 634.1ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000085.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000085.png\n",
      "\n",
      "Processing: 000086.png\n",
      "\n",
      "0: 224x640 6 persons, 2 bicycles, 1 truck, 625.8ms\n",
      "Speed: 1.5ms preprocess, 625.8ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000086.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000086.png\n",
      "\n",
      "Processing: 000087.png\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 1 truck, 630.8ms\n",
      "Speed: 1.4ms preprocess, 630.8ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000087.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000087.png\n",
      "\n",
      "Processing: 000088.png\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 1 truck, 639.4ms\n",
      "Speed: 2.1ms preprocess, 639.4ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000088.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000088.png\n",
      "\n",
      "Processing: 000089.png\n",
      "\n",
      "0: 224x640 5 persons, 3 bicycles, 1 truck, 635.5ms\n",
      "Speed: 1.5ms preprocess, 635.5ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000089.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000089.png\n",
      "\n",
      "Processing: 000090.png\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 1 truck, 769.5ms\n",
      "Speed: 1.6ms preprocess, 769.5ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000090.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000090.png\n",
      "\n",
      "Processing: 000091.png\n",
      "\n",
      "0: 224x640 7 persons, 3 bicycles, 1 truck, 625.9ms\n",
      "Speed: 1.3ms preprocess, 625.9ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000091.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000091.png\n",
      "\n",
      "Processing: 000092.png\n",
      "\n",
      "0: 224x640 7 persons, 3 bicycles, 1 truck, 663.8ms\n",
      "Speed: 1.7ms preprocess, 663.8ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000092.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000092.png\n",
      "\n",
      "Processing: 000093.png\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 1 truck, 684.4ms\n",
      "Speed: 1.5ms preprocess, 684.4ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000093.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000093.png\n",
      "\n",
      "Processing: 000094.png\n",
      "\n",
      "0: 224x640 7 persons, 2 bicycles, 1 truck, 889.5ms\n",
      "Speed: 1.5ms preprocess, 889.5ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000094.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000094.png\n",
      "\n",
      "Processing: 000095.png\n",
      "\n",
      "0: 224x640 6 persons, 2 bicycles, 1 truck, 629.9ms\n",
      "Speed: 2.6ms preprocess, 629.9ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000095.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000095.png\n",
      "\n",
      "Processing: 000096.png\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 1 truck, 629.2ms\n",
      "Speed: 1.4ms preprocess, 629.2ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000096.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000096.png\n",
      "\n",
      "Processing: 000097.png\n",
      "\n",
      "0: 224x640 5 persons, 2 bicycles, 1 truck, 626.7ms\n",
      "Speed: 1.5ms preprocess, 626.7ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000097.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000097.png\n",
      "\n",
      "Processing: 000098.png\n",
      "\n",
      "0: 224x640 8 persons, 2 bicycles, 1 truck, 645.9ms\n",
      "Speed: 1.5ms preprocess, 645.9ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000098.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000098.png\n",
      "\n",
      "Processing: 000099.png\n",
      "\n",
      "0: 224x640 6 persons, 2 bicycles, 1 truck, 625.4ms\n",
      "Speed: 1.5ms preprocess, 625.4ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000099.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000099.png\n",
      "\n",
      "Processing: 000100.png\n",
      "\n",
      "0: 224x640 7 persons, 3 bicycles, 1 truck, 619.8ms\n",
      "Speed: 1.6ms preprocess, 619.8ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000100.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000100.png\n",
      "\n",
      "Processing: 000101.png\n",
      "\n",
      "0: 224x640 6 persons, 2 bicycles, 1 truck, 619.1ms\n",
      "Speed: 1.7ms preprocess, 619.1ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000101.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000101.png\n",
      "\n",
      "Processing: 000102.png\n",
      "\n",
      "0: 224x640 6 persons, 3 bicycles, 1 truck, 763.4ms\n",
      "Speed: 1.5ms preprocess, 763.4ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000102.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000102.png\n",
      "\n",
      "Processing: 000103.png\n",
      "\n",
      "0: 224x640 6 persons, 2 bicycles, 1 truck, 644.9ms\n",
      "Speed: 1.5ms preprocess, 644.9ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000103.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000103.png\n",
      "\n",
      "Processing: 000104.png\n",
      "\n",
      "0: 224x640 6 persons, 3 bicycles, 1 truck, 620.3ms\n",
      "Speed: 1.5ms preprocess, 620.3ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000104.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000104.png\n",
      "\n",
      "Processing: 000105.png\n",
      "\n",
      "0: 224x640 7 persons, 3 bicycles, 1 truck, 619.7ms\n",
      "Speed: 1.4ms preprocess, 619.7ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000105.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000105.png\n",
      "\n",
      "Processing: 000106.png\n",
      "\n",
      "0: 224x640 6 persons, 3 bicycles, 1 truck, 647.6ms\n",
      "Speed: 1.6ms preprocess, 647.6ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000106.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000106.png\n",
      "\n",
      "Processing: 000107.png\n",
      "\n",
      "0: 224x640 7 persons, 3 bicycles, 1 truck, 621.8ms\n",
      "Speed: 1.5ms preprocess, 621.8ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000107.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000107.png\n",
      "\n",
      "Processing: 000108.png\n",
      "\n",
      "0: 224x640 7 persons, 2 bicycles, 1 truck, 625.3ms\n",
      "Speed: 1.5ms preprocess, 625.3ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000108.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000108.png\n",
      "\n",
      "Processing: 000109.png\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 1 truck, 621.4ms\n",
      "Speed: 1.8ms preprocess, 621.4ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000109.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000109.png\n",
      "\n",
      "Processing: 000110.png\n",
      "\n",
      "0: 224x640 6 persons, 1 bicycle, 1 truck, 613.3ms\n",
      "Speed: 1.5ms preprocess, 613.3ms inference, 1.1ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000110.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000110.png\n",
      "\n",
      "Processing: 000111.png\n",
      "\n",
      "0: 224x640 8 persons, 1 bicycle, 1 truck, 609.7ms\n",
      "Speed: 1.5ms preprocess, 609.7ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000111.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000111.png\n",
      "\n",
      "Processing: 000112.png\n",
      "\n",
      "0: 224x640 6 persons, 2 bicycles, 1 truck, 623.6ms\n",
      "Speed: 1.5ms preprocess, 623.6ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000112.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000112.png\n",
      "\n",
      "Processing: 000113.png\n",
      "\n",
      "0: 224x640 6 persons, 2 bicycles, 1 truck, 628.5ms\n",
      "Speed: 1.7ms preprocess, 628.5ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000113.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000113.png\n",
      "\n",
      "Processing: 000114.png\n",
      "\n",
      "0: 224x640 5 persons, 1 bicycle, 1 truck, 758.0ms\n",
      "Speed: 1.7ms preprocess, 758.0ms inference, 1.4ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000114.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000114.png\n",
      "\n",
      "Processing: 000115.png\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 1 truck, 612.7ms\n",
      "Speed: 1.8ms preprocess, 612.7ms inference, 1.0ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000115.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000115.png\n",
      "\n",
      "Processing: 000116.png\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 1 truck, 622.4ms\n",
      "Speed: 1.6ms preprocess, 622.4ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000116.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000116.png\n",
      "\n",
      "Processing: 000117.png\n",
      "\n",
      "0: 224x640 4 persons, 2 bicycles, 1 truck, 618.5ms\n",
      "Speed: 1.5ms preprocess, 618.5ms inference, 0.9ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000117.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000117.png\n",
      "\n",
      "Processing: 000118.png\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 1 truck, 619.9ms\n",
      "Speed: 1.6ms preprocess, 619.9ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000118.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000118.png\n",
      "\n",
      "Processing: 000119.png\n",
      "\n",
      "0: 224x640 4 persons, 1 bicycle, 1 truck, 621.5ms\n",
      "Speed: 1.4ms preprocess, 621.5ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000119.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000119.png\n",
      "\n",
      "Processing: 000120.png\n",
      "\n",
      "0: 224x640 4 persons, 2 bicycles, 1 truck, 660.6ms\n",
      "Speed: 1.4ms preprocess, 660.6ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000120.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000120.png\n",
      "\n",
      "Processing: 000121.png\n",
      "\n",
      "0: 224x640 4 persons, 2 bicycles, 1 truck, 609.0ms\n",
      "Speed: 1.5ms preprocess, 609.0ms inference, 1.3ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000121.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000121.png\n",
      "\n",
      "Processing: 000122.png\n",
      "\n",
      "0: 224x640 4 persons, 2 bicycles, 1 truck, 631.1ms\n",
      "Speed: 1.5ms preprocess, 631.1ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000122.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000122.png\n",
      "\n",
      "Processing: 000123.png\n",
      "\n",
      "0: 224x640 4 persons, 2 bicycles, 1 truck, 640.7ms\n",
      "Speed: 1.8ms preprocess, 640.7ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000123.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000123.png\n",
      "\n",
      "Processing: 000124.png\n",
      "\n",
      "0: 224x640 3 persons, 2 bicycles, 1 truck, 611.3ms\n",
      "Speed: 1.5ms preprocess, 611.3ms inference, 1.1ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000124.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000124.png\n",
      "\n",
      "Processing: 000125.png\n",
      "\n",
      "0: 224x640 3 persons, 2 bicycles, 1 truck, 622.6ms\n",
      "Speed: 1.3ms preprocess, 622.6ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000125.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000125.png\n",
      "\n",
      "Processing: 000126.png\n",
      "\n",
      "0: 224x640 3 persons, 1 bicycle, 1 truck, 753.0ms\n",
      "Speed: 1.4ms preprocess, 753.0ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000126.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000126.png\n",
      "\n",
      "Processing: 000127.png\n",
      "\n",
      "0: 224x640 3 persons, 1 bicycle, 1 truck, 620.2ms\n",
      "Speed: 1.7ms preprocess, 620.2ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000127.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000127.png\n",
      "\n",
      "Processing: 000128.png\n",
      "\n",
      "0: 224x640 3 persons, 1 bicycle, 1 truck, 616.2ms\n",
      "Speed: 1.4ms preprocess, 616.2ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000128.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000128.png\n",
      "\n",
      "Processing: 000129.png\n",
      "\n",
      "0: 224x640 3 persons, 2 bicycles, 1 truck, 608.9ms\n",
      "Speed: 1.4ms preprocess, 608.9ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000129.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000129.png\n",
      "\n",
      "Processing: 000130.png\n",
      "\n",
      "0: 224x640 3 persons, 3 bicycles, 1 truck, 614.0ms\n",
      "Speed: 1.5ms preprocess, 614.0ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000130.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000130.png\n",
      "\n",
      "Processing: 000131.png\n",
      "\n",
      "0: 224x640 3 persons, 1 bicycle, 1 truck, 619.7ms\n",
      "Speed: 1.7ms preprocess, 619.7ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000131.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000131.png\n",
      "\n",
      "Processing: 000132.png\n",
      "\n",
      "0: 224x640 3 persons, 2 bicycles, 1 truck, 627.7ms\n",
      "Speed: 1.5ms preprocess, 627.7ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000132.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000132.png\n",
      "\n",
      "Processing: 000133.png\n",
      "\n",
      "0: 224x640 3 persons, 1 bicycle, 1 truck, 869.5ms\n",
      "Speed: 1.5ms preprocess, 869.5ms inference, 3.1ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000133.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000133.png\n",
      "\n",
      "Processing: 000134.png\n",
      "\n",
      "0: 224x640 3 persons, 2 bicycles, 1 truck, 699.2ms\n",
      "Speed: 1.4ms preprocess, 699.2ms inference, 1.1ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000134.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000134.png\n",
      "\n",
      "Processing: 000135.png\n",
      "\n",
      "0: 224x640 3 persons, 2 bicycles, 1 truck, 645.7ms\n",
      "Speed: 1.4ms preprocess, 645.7ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000135.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000135.png\n",
      "\n",
      "Processing: 000136.png\n",
      "\n",
      "0: 224x640 3 persons, 2 bicycles, 1 truck, 655.9ms\n",
      "Speed: 1.4ms preprocess, 655.9ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000136.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000136.png\n",
      "\n",
      "Processing: 000137.png\n",
      "\n",
      "0: 224x640 3 persons, 2 bicycles, 1 truck, 797.4ms\n",
      "Speed: 1.5ms preprocess, 797.4ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000137.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000137.png\n",
      "\n",
      "Processing: 000138.png\n",
      "\n",
      "0: 224x640 3 persons, 2 bicycles, 1 truck, 641.9ms\n",
      "Speed: 1.9ms preprocess, 641.9ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000138.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000138.png\n",
      "\n",
      "Processing: 000139.png\n",
      "\n",
      "0: 224x640 3 persons, 2 bicycles, 1 truck, 647.8ms\n",
      "Speed: 1.5ms preprocess, 647.8ms inference, 0.7ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000139.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000139.png\n",
      "\n",
      "Processing: 000140.png\n",
      "\n",
      "0: 224x640 3 persons, 1 bicycle, 1 truck, 647.7ms\n",
      "Speed: 2.3ms preprocess, 647.7ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000140.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000140.png\n",
      "\n",
      "Processing: 000141.png\n",
      "\n",
      "0: 224x640 3 persons, 1 bicycle, 1 truck, 639.7ms\n",
      "Speed: 1.4ms preprocess, 639.7ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000141.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000141.png\n",
      "\n",
      "Processing: 000142.png\n",
      "\n",
      "0: 224x640 3 persons, 2 bicycles, 1 truck, 637.2ms\n",
      "Speed: 1.5ms preprocess, 637.2ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000142.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000142.png\n",
      "\n",
      "Processing: 000143.png\n",
      "\n",
      "0: 224x640 3 persons, 1 bicycle, 1 truck, 643.8ms\n",
      "Speed: 1.6ms preprocess, 643.8ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000143.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000143.png\n",
      "\n",
      "Processing: 000144.png\n",
      "\n",
      "0: 224x640 2 persons, 1 bicycle, 1 truck, 641.6ms\n",
      "Speed: 2.0ms preprocess, 641.6ms inference, 0.8ms postprocess per image at shape (1, 3, 224, 640)\n",
      "Detections for 000144.png:\n",
      "Skipped detection for unwanted class: bicycle\n",
      "Saved: outputs/000144.png\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize the YOLO model\n",
    "model = YOLO(\"yolov8l.pt\")   # Moved to parameters \n",
    "\n",
    "# Initialize SORT tracker\n",
    "mot_tracker = Sort(max_age=1, min_hits=3, iou_threshold=0.3) # Not important for yolo\n",
    "\n",
    "# Define input and output folders\n",
    "data_folder_1 = \"data/view1\"  # Folder containing input frames\n",
    "data_folder_2 = \"data/view2\"  # Folder containing input frames\n",
    "output_folder = \"outputs\"     # Folder to save output frames\n",
    "os.makedirs(output_folder, exist_ok=True)  # Create the output folder if it doesn't exist\n",
    "\n",
    "# Process images in the input folder\n",
    "for frame_path in sorted(Path(data_folder_1).glob(\"*.png\")):  # Adjust pattern for your image format\n",
    "    print(f\"Processing: {frame_path.name}\")\n",
    "    \n",
    "    # Load the image\n",
    "    img = cv2.imread(str(frame_path))\n",
    "    if img is None:\n",
    "        print(f\"Error: Could not load image {frame_path.name}\")\n",
    "        continue\n",
    "    \n",
    "    # Perform object detection\n",
    "    results = model(img,conf=0.5, classes=[0,1,2,7])\n",
    "    detections = results[0].boxes  # Access detection results\n",
    "    \n",
    "    print(f\"Detections for {frame_path.name}:\")\n",
    "\n",
    "    dets = []\n",
    "    # Process each detection\n",
    "    for box in detections:\n",
    "        # Extract bounding box coordinates, confidence, and class\n",
    "        x1, y1, x2, y2 = box.xyxy[0].tolist()  # Bounding box: [x1, y1, x2, y2]\n",
    "        confidence = float(box.conf[0])        # Confidence score\n",
    "        cls = int(box.cls[0])                  # Class index\n",
    "        label = model.names[cls]               # Class name\n",
    "        \n",
    "        # Skip detections with low confidence\n",
    "        if confidence < 0.5:\n",
    "            print(f\"Skipped detection with low confidence: {confidence:.2f}\")\n",
    "            continue\n",
    "\n",
    "        # Filter out unwanted classes\n",
    "        if label not in [\"person\", \"car\", \"truck\"]:\n",
    "            print(f\"Skipped detection for unwanted class: {label}\")\n",
    "            continue\n",
    "\n",
    "        # Print detection information\n",
    "        #print(f\"Class: {label}, Confidence: {confidence:.2f}, \"\n",
    "        #      f\"BBox: ({x1:.2f}, {y1:.2f}, {x2:.2f}, {y2:.2f})\")\n",
    "        \n",
    "                # Add detection to SORT input\n",
    "        dets.append([x1, y1, x2, y2, confidence])\n",
    "    \n",
    "\n",
    "    dets = np.array(dets)  # Convert list to numpy array for SORT\n",
    "\n",
    "    # Update SORT tracker with current frame detections\n",
    "    trackers = mot_tracker.update(dets)\n",
    "\n",
    "    # Annotate the frame with tracking results\n",
    "    for d in trackers:\n",
    "        x1, y1, x2, y2, track_id = map(int, d)  # Tracker output [x1, y1, x2, y2, ID]\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Draw bounding box\n",
    "        cv2.putText(img, f\"ID: {track_id}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)  # Add track ID\n",
    "\n",
    "    # Save the annotated frame\n",
    "    output_path = os.path.join(output_folder, frame_path.name)\n",
    "    cv2.imwrite(output_path, img)\n",
    "    print(f\"Saved: {output_path}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    # Annotate the frame with detections\n",
    "    #annotated_frame = results[0].plot()\n",
    "    \n",
    "    # Save the processed frame\n",
    "    #output_path = os.path.join(output_folder, frame_path.name)\n",
    "    #cv2.imwrite(output_path, annotated_frame)\n",
    "    #print(f\"Saved: {output_path}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "#results = model(\"./data/view1/000000.png\", show=True)\n",
    "#cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--display] [--seq_path SEQ_PATH]\n",
      "                             [--phase PHASE] [--max_age MAX_AGE]\n",
      "                             [--min_hits MIN_HITS]\n",
      "                             [--iou_threshold IOU_THRESHOLD]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=/Users/dani/Library/Jupyter/runtime/kernel-v3b918768b0b646ac0cdfc49f9fe046de38f90c00f.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/pfas/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE PARAMETERS:\n",
    "model = YOLO(\"yolov8l.pt\")\n",
    "source_1=\"data/view1\"\n",
    "source_2=\"data/view2\"\n",
    "device=\"cpu\"\n",
    "save_path = \"outputs\"\n",
    "\n",
    "image_size=(512, 512)\n",
    "conf_thres=0.5\n",
    "max_det=20\n",
    "line_thickness=2\n",
    "iou_thres=0.45\n",
    "\n",
    "save_txt=True\n",
    "save_csv=False\n",
    "nosave=False\n",
    "hide_labels=False \n",
    "hide_conf=True\n",
    "\n",
    "# DEFINE PARAMETERS FOR SORT:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectDetector:\n",
    "    def __init__(self, device, weights, source_1, source_2, image_size, save_path, sort_max_age=10, sort_min_hits=3, sort_iou_thresh=0.3):\n",
    "        self.device = select_device(device)\n",
    "        #self.model = DetectMultiBackend(weights, self.device)\n",
    "        #self.model.names = dict(list(self.model.names.items())[:2] + list(self.model.names.items())[4:])\n",
    "        #self.stride, self.names, self.pt = self.model.stride, self.model.names, self.model.pt\n",
    "        self.imgsz = image_size\n",
    "        #self.model.warmup(imgsz=(1, 3, *self.imgsz))\n",
    "        self.dt = Profile(device=self.device)\n",
    "        self.source_1 = Path(source_1)\n",
    "        self.source_2 = Path(source_2)\n",
    "        self.files_1 = [f for f in self.source_1.glob('*') if f.suffix.lower() in ['.jpg', '.jpeg', '.png']]\n",
    "        self.files_2 = [f for f in self.source_2.glob('*') if f.suffix.lower() in ['.jpg', '.jpeg', '.png']]\n",
    "        \n",
    "        self.save_path = save_path\n",
    "        if not os.path.exists(self.save_path):\n",
    "            os.makedirs(self.save_path)\n",
    "        \n",
    "        # Initialize SORT Tracker\n",
    "        self.sort_tracker = Sort(max_age=sort_max_age, min_hits=sort_min_hits, iou_threshold=sort_iou_thresh)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for file_1, file_2 in zip_longest(self.files_1, self.files_2, fillvalue=None):\n",
    "            img_1 = cv2.imread(str(file_1))\n",
    "            img_2 = cv2.imread(str(file_2))\n",
    "            yield (img_1, img_2)\n",
    "    \n",
    "    def draw_boxes(self, img, bbox, identities=None, categories=None, names=None, offset=(0, 0)):\n",
    "        for i, box in enumerate(bbox):\n",
    "            x1, y1, x2, y2 = [int(i) for i in box]\n",
    "            x1 += offset[0]\n",
    "            x2 += offset[0]\n",
    "            y1 += offset[1]\n",
    "            y2 += offset[1]\n",
    "            id = int(identities[i]) if identities is not None else 0\n",
    "            data = (int((box[0] + box[2]) / 2), int((box[1] + box[3]) / 2))\n",
    "            label = f\"{id} {names[int(categories[i])]}\" if categories is not None else str(id)\n",
    "\n",
    "            color = self.compute_color_for_labels(id)\n",
    "            (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.rectangle(img, (x1, y1 - 20), (x1 + w, y1), (255, 191, 0), -1)\n",
    "            cv2.putText(img, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, [255, 255, 255], 1)\n",
    "            cv2.circle(img, data, 3, color, -1)\n",
    "\n",
    "        return img\n",
    "    \n",
    "    @smart_inference_mode()\n",
    "    def detect_object_2D(self, im, frame_num, save_images):\n",
    "        with self.dt:\n",
    "            image_original = im\n",
    "            im = letterbox(im, self.imgsz, stride=self.stride, auto=True)[0]\n",
    "            im = im.transpose((2, 0, 1))[::-1]\n",
    "            im = np.ascontiguousarray(im)\n",
    "            im = torch.from_numpy(im).to(self.device)\n",
    "            im = im.float().unsqueeze(0)\n",
    "            im /= 255\n",
    "            \n",
    "            pred = self.model(im)\n",
    "            pred = non_max_suppression(pred)\n",
    "            \n",
    "            for det in pred:\n",
    "                gn = torch.tensor(image_original.shape)[[1, 0, 1, 0]] #Normalization\n",
    "                det[:, :4] = scale_boxes(im.shape[2:], det[:, :4], image_original.shape).round() # Rescale to original size\n",
    "                \n",
    "                dets_to_sort = np.empty((0, 6))\n",
    "                for *xyxy, conf, cls in reversed(det):\n",
    "                    if cls not in [0, 1, 4]:\n",
    "                        continue\n",
    "                    \n",
    "                    c = int(cls)\n",
    "                    coords = ((xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist())  # Normalized xywh\n",
    "                    #{conf:.2f}\", *coords\n",
    "                    # Agregar detección a dets_to_sort para clases 0 y 1\n",
    "                    x1, y1, x2, y2 = [int(coord) for coord in xyxy]\n",
    "                    dets_to_sort = np.vstack((dets_to_sort, np.array([x1, y1, x2, y2, conf, c])))\n",
    "                \n",
    "                # Update SORT tracker\n",
    "                tracked_dets = self.sort_tracker.update(dets_to_sort)\n",
    "\n",
    "                # Draw tracked bounding boxes\n",
    "                if len(tracked_dets) > 0:\n",
    "                    bbox_xyxy = tracked_dets[:, :4]\n",
    "                    identities = tracked_dets[:, 4]  # Object IDs\n",
    "                    categories = [0] * len(identities)  # Placeholder for categories if needed\n",
    "                    self.draw_boxes(image_original, bbox_xyxy, identities, categories, self.names)\n",
    "            \n",
    "            # Save or display the resulting frame\n",
    "            if save_images:\n",
    "                save_path = os.path.join(self.save_path, f\"{frame_num}.png\")\n",
    "                cv2.imwrite(save_path, image_original)\n",
    "\n",
    "    def compute_color_for_labels(self, label, palette=(2 ** 11 - 1, 2 ** 15 - 1, 2 ** 20 - 1)):\n",
    "        color = [int((p * (label ** 2 - label + 1)) % 255) for p in palette]\n",
    "        return tuple(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: cannot change to '/Users/dani/Desktop/MS_AutonomousSystems/Perception_for_Autonomous_systems/Final': No such file or directory\n",
      "YOLOv5 🚀 2024-11-21 Python-3.10.14 torch-2.2.2 CPU\n",
      "\n"
     ]
    }
   ],
   "source": [
    "detector = ObjectDetector(device, weights, source_1, source_2, image_size, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Z ESTIMATION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance_to_object(left_center, right_center, im_left, im_right, focal_length = 707.0493, baseline = 0.06):\n",
    "\n",
    "    # Calculate disparity (horizontal pixel difference between the left and right image)\n",
    "    disparity = abs(left_center[0] - right_center[0])\n",
    "    \n",
    "    if disparity == 0:\n",
    "        return float('inf')\n",
    "    \n",
    "    Z = (focal_length * baseline) / disparity\n",
    "    \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, images \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(detector):\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_object_2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_images\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m#detector.detect_object_2D(images[1], save_path=output, frame_num=i)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/pfas/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 59\u001b[0m, in \u001b[0;36mObjectDetector.detect_object_2D\u001b[0;34m(self, im, frame_num, save_images)\u001b[0m\n\u001b[1;32m     56\u001b[0m im \u001b[38;5;241m=\u001b[39m im\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     57\u001b[0m im \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n\u001b[0;32m---> 59\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m pred \u001b[38;5;241m=\u001b[39m non_max_suppression(pred)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m det \u001b[38;5;129;01min\u001b[39;00m pred:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/pfas/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/pfas/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/MS_AutonomousSystems/Perception_for_Autonomous_systems/Final project/YoloV5_full/yolov5_object_track/models/common.py:688\u001b[0m, in \u001b[0;36mDetectMultiBackend.forward\u001b[0;34m(self, im, augment, visualize)\u001b[0m\n\u001b[1;32m    685\u001b[0m     im \u001b[38;5;241m=\u001b[39m im\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# torch BCHW to numpy BHWC shape(1,320,192,3)\u001b[39;00m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt:  \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[0;32m--> 688\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im, augment\u001b[38;5;241m=\u001b[39maugment, visualize\u001b[38;5;241m=\u001b[39mvisualize) \u001b[38;5;28;01mif\u001b[39;00m augment \u001b[38;5;129;01mor\u001b[39;00m visualize \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:  \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/pfas/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/pfas/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/MS_AutonomousSystems/Perception_for_Autonomous_systems/Final project/YoloV5_full/yolov5_object_track/models/yolo.py:270\u001b[0m, in \u001b[0;36mDetectionModel.forward\u001b[0;34m(self, x, augment, profile, visualize)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_augment(x)  \u001b[38;5;66;03m# augmented inference, None\u001b[39;00m\n\u001b[0;32m--> 270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/MS_AutonomousSystems/Perception_for_Autonomous_systems/Final project/YoloV5_full/yolov5_object_track/models/yolo.py:169\u001b[0m, in \u001b[0;36mBaseModel._forward_once\u001b[0;34m(self, x, profile, visualize)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[0;32m--> 169\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[1;32m    170\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/pfas/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/pfas/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/MS_AutonomousSystems/Perception_for_Autonomous_systems/Final project/YoloV5_full/yolov5_object_track/models/common.py:91\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     90\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Applies a fused convolution and activation function to the input tensor `x`.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/pfas/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/pfas/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/pfas/lib/python3.10/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/pfas/lib/python3.10/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, images in enumerate(detector):\n",
    "    detector.detect_object_2D(images[0], frame_num=i, save_images=True)\n",
    "    #detector.detect_object_2D(images[1], save_path=output, frame_num=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Video from frames -><h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved as output_video.mp4\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Define paths\n",
    "data_folder = \"./outputs\"  # Folder containing the images\n",
    "output_video = \"output_video.mp4\"  # Output video file\n",
    "\n",
    "# Video settings\n",
    "frame_rate = 30  # Frames per second\n",
    "frame_size = None\n",
    "\n",
    "# Collect all image paths, sorted by name\n",
    "image_paths = sorted(Path(data_folder).glob(\"*.png\"))  # Adjust the pattern to match your image format\n",
    "\n",
    "# Check if there are images to process\n",
    "if not image_paths:\n",
    "    raise ValueError(f\"No images found in {data_folder}\")\n",
    "\n",
    "# Read the first image to get the frame size\n",
    "first_image = cv2.imread(str(image_paths[0]))\n",
    "if first_image is None:\n",
    "    raise ValueError(\"Could not read the first image. Check the image path and format.\")\n",
    "frame_size = (first_image.shape[1], first_image.shape[0])  # (width, height)\n",
    "\n",
    "# Define the video writer with the correct codec\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for mp4\n",
    "out = cv2.VideoWriter(output_video, fourcc, frame_rate, frame_size)\n",
    "\n",
    "# Write each image to the video\n",
    "for image_path in image_paths:\n",
    "    frame = cv2.imread(str(image_path))\n",
    "    if frame is None:\n",
    "        print(f\"Warning: Could not read image {image_path}, skipping.\")\n",
    "        continue\n",
    "    resized_frame = cv2.resize(frame, frame_size)  # Ensure consistent size\n",
    "    out.write(resized_frame)\n",
    "\n",
    "# Release the video writer\n",
    "out.release()\n",
    "print(f\"Video saved as {output_video}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
